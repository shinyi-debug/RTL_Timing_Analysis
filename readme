# RTL Timing Violation Analysis Using Machine Learning

## **Overview**
Timing analysis is a crucial step in digital circuit design, ensuring that signals meet timing constraints. Traditional synthesis-based tools take a long time to generate timing reports, leading to delayed iterations. This project introduces an **AI-driven approach** to predict **combinational logic depth** and detect **timing violations** before synthesis.

By using **graph-based netlist representation** and **machine learning models**, the tool enables designers to detect timing issues early, reducing dependency on slow synthesis tools and speeding up the development cycle.

---

## **Features**
âœ” **Graph-based RTL Analysis** â€“ Constructs a **Directed Acyclic Graph (DAG)** representation of the RTL circuit.  
âœ” **Machine Learning Predictions** â€“ Uses **Gradient Boosting Classifier** for predicting timing violations.  
âœ” **Feature Engineering** â€“ Extracts features like **fan-in, fan-out, depth, gate count, wire length, and clock skew**.  
âœ” **AMD UG949 Integration** â€“ Implements **timing constraints and setup/hold timing considerations** from AMD methodologies.  
âœ” **Fast & Efficient** â€“ Provides **millisecond-level** predictions compared to **minutes/hours** required for synthesis.  
âœ” **Real Dataset Training** â€“ Trained using **Yosys/Vivado synthesis reports** and OpenCores designs.  

---

## **Project Structure**
```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rtl_parser.py       # Parses RTL and builds graph
â”‚   â”œâ”€â”€ ml_model.py         # ML model for timing prediction
â”‚   â”œâ”€â”€ feature_engineering.py # Feature extraction logic
â”‚   â”œâ”€â”€ utils.py            # Helper functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ real_timing_data.csv  # Real synthesis timing data
â”‚   â”œâ”€â”€ synthetic_data.csv    # Generated dataset
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_rtl_parser.py   # Unit tests for RTL parser
â”‚   â”œâ”€â”€ test_ml_model.py     # Unit tests for ML model
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ analysis.ipynb       # Jupyter Notebook for model evaluation
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ README.md                # Project Documentation
â”œâ”€â”€ setup.py                 # Installation script
â””â”€â”€ pyproject.toml           # Build system
```

---

## **Installation & Setup**
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/shinyi-debug/RTL_Timing_Analysis.git
cd RTL_Timing_Analysis
```

### **2ï¸âƒ£ Create & Activate Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate   # For macOS/Linux
venv\Scripts\activate      # For Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

---

## **How to Run the Project**
### **ğŸ”¹ Running the RTL Parser & ML Prediction**
```bash
python src/rtl_parser.py --input design.v --signal clk
```
### **ğŸ”¹ Running Unit Tests**
```bash
pytest tests/
```
### **ğŸ”¹ Running Jupyter Notebook for Analysis**
```bash
jupyter notebook notebooks/analysis.ipynb
```

---

## **Approach Used**
1ï¸âƒ£ **Graph Representation of RTL** â†’ Builds a **DAG** representation of the circuit.  
2ï¸âƒ£ **Feature Engineering** â†’ Extracts **fan-in, fan-out, depth, clock skew, etc.**.  
3ï¸âƒ£ **Machine Learning Model** â†’ **Gradient Boosting Classifier** trained on real & synthetic datasets.  
4ï¸âƒ£ **Integration of AMD UG949 Methodology** â†’ Includes **timing constraints & validation**.  
5ï¸âƒ£ **Performance Optimization** â†’ Achieves **millisecond-level** prediction speed.  

---

## **Proof of Correctness**
âœ” **Validated against Synthesis Reports** â†’ Compared against **Yosys/Vivado timing reports**.  
âœ” **Cross-Validation** â†’ Applied **k-fold validation** to ensure generalization.  
âœ” **MAE Accuracy Metric** â†’ Mean Absolute Error (MAE) used to compare predicted vs. actual depth.  
âœ” **Real RTL Testing** â†’ Tested on **OpenCores & RISC-V processor designs**.  

---

## **Complexity Analysis**
- **Graph Construction**: `O(V + E)`  
- **Feature Extraction**: `O(N)`  
- **ML Model Complexity**: `O(K * N log N)`  
- **Overall Runtime**: **Milliseconds vs. Minutes (Synthesis Tools)**  

---

## **Alternatives Considered**
ğŸ”¹ **Rule-Based Heuristics** â€“ Simple but **less accurate & scalable**.  
ğŸ”¹ **Full Synthesis-Based Analysis** â€“ **Accurate but slow**.  
ğŸ”¹ **Deep Learning (GNNs)** â€“ Potentially powerful but **high training cost**.  
âœ… **Final Choice:** **Hybrid Graph + ML Approach (Gradient Boosting)** for **speed & accuracy**.  

---

## **References & Resources**
ğŸ“Œ **Datasets Used:** OpenCores, RISC-V, AMD FPGA designs.  
ğŸ“Œ **Synthesis Tools:** Yosys, Vivado, Synopsys DC.  
ğŸ“Œ **Python Libraries:** `networkx`, `pandas`, `scikit-learn`, `matplotlib`, `joblib`, `numpy`.  

---

## **Contributing**
1. **Fork the Repository**
2. **Create a New Branch**
3. **Make Your Changes & Test**
4. **Submit a Pull Request**

---

## **License**
MIT License - Open Source Contribution Welcome! ğŸš€

