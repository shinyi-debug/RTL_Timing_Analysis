# RTL Timing Violation Analysis Using Machine Learning

## **Overview**
Timing analysis is a crucial step in digital circuit design, ensuring that signals meet timing constraints. Traditional synthesis-based tools take a long time to generate timing reports, leading to delayed iterations. This project introduces an **AI-driven approach** to predict **combinational logic depth** and detect **timing violations** before synthesis.

By using **graph-based netlist representation** and **machine learning models**, the tool enables designers to detect timing issues early, reducing dependency on slow synthesis tools and speeding up the development cycle.

---

## **Features**
✔ **Graph-based RTL Analysis** – Constructs a **Directed Acyclic Graph (DAG)** representation of the RTL circuit.  
✔ **Machine Learning Predictions** – Uses **Gradient Boosting Classifier** for predicting timing violations.  
✔ **Feature Engineering** – Extracts features like **fan-in, fan-out, depth, gate count, wire length, and clock skew**.  
✔ **AMD UG949 Integration** – Implements **timing constraints and setup/hold timing considerations** from AMD methodologies.  
✔ **Fast & Efficient** – Provides **millisecond-level** predictions compared to **minutes/hours** required for synthesis.  
✔ **Real Dataset Training** – Trained using **Yosys/Vivado synthesis reports** and OpenCores designs.  

---

## **Project Structure**
```
├── src/
│   ├── rtl_parser.py       # Parses RTL and builds graph
│   ├── ml_model.py         # ML model for timing prediction
│   ├── feature_engineering.py # Feature extraction logic
│   ├── utils.py            # Helper functions
├── data/
│   ├── real_timing_data.csv  # Real synthesis timing data
│   ├── synthetic_data.csv    # Generated dataset
├── tests/
│   ├── test_rtl_parser.py   # Unit tests for RTL parser
│   ├── test_ml_model.py     # Unit tests for ML model
├── notebooks/
│   ├── analysis.ipynb       # Jupyter Notebook for model evaluation
├── requirements.txt         # Dependencies
├── README.md                # Project Documentation
├── setup.py                 # Installation script
└── pyproject.toml           # Build system
```

---

## **Installation & Setup**
### **1️⃣ Clone the Repository**
```bash
git clone https://github.com/shinyi-debug/RTL_Timing_Analysis.git
cd RTL_Timing_Analysis
```

### **2️⃣ Create & Activate Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate   # For macOS/Linux
venv\Scripts\activate      # For Windows
```

### **3️⃣ Install Dependencies**
```bash
pip install -r requirements.txt
```

---

## **How to Run the Project**
### **🔹 Running the RTL Parser & ML Prediction**
```bash
python src/rtl_parser.py --input design.v --signal clk
```
### **🔹 Running Unit Tests**
```bash
pytest tests/
```
### **🔹 Running Jupyter Notebook for Analysis**
```bash
jupyter notebook notebooks/analysis.ipynb
```

---

## **Approach Used**
1️⃣ **Graph Representation of RTL** → Builds a **DAG** representation of the circuit.  
2️⃣ **Feature Engineering** → Extracts **fan-in, fan-out, depth, clock skew, etc.**.  
3️⃣ **Machine Learning Model** → **Gradient Boosting Classifier** trained on real & synthetic datasets.  
4️⃣ **Integration of AMD UG949 Methodology** → Includes **timing constraints & validation**.  
5️⃣ **Performance Optimization** → Achieves **millisecond-level** prediction speed.  

---

## **Proof of Correctness**
✔ **Validated against Synthesis Reports** → Compared against **Yosys/Vivado timing reports**.  
✔ **Cross-Validation** → Applied **k-fold validation** to ensure generalization.  
✔ **MAE Accuracy Metric** → Mean Absolute Error (MAE) used to compare predicted vs. actual depth.  
✔ **Real RTL Testing** → Tested on **OpenCores & RISC-V processor designs**.  

---

## **Complexity Analysis**
- **Graph Construction**: `O(V + E)`  
- **Feature Extraction**: `O(N)`  
- **ML Model Complexity**: `O(K * N log N)`  
- **Overall Runtime**: **Milliseconds vs. Minutes (Synthesis Tools)**  

---

## **Alternatives Considered**
🔹 **Rule-Based Heuristics** – Simple but **less accurate & scalable**.  
🔹 **Full Synthesis-Based Analysis** – **Accurate but slow**.  
🔹 **Deep Learning (GNNs)** – Potentially powerful but **high training cost**.  
✅ **Final Choice:** **Hybrid Graph + ML Approach (Gradient Boosting)** for **speed & accuracy**.  

---

## **References & Resources**
📌 **Datasets Used:** OpenCores, RISC-V, AMD FPGA designs.  
📌 **Synthesis Tools:** Yosys, Vivado, Synopsys DC.  
📌 **Python Libraries:** `networkx`, `pandas`, `scikit-learn`, `matplotlib`, `joblib`, `numpy`.  

---

## **Contributing**
1. **Fork the Repository**
2. **Create a New Branch**
3. **Make Your Changes & Test**
4. **Submit a Pull Request**

---

## **License**
MIT License - Open Source Contribution Welcome! 🚀

